# 从零开始组装一个基因组

什么是基因组？你的生命之书。你所有的基因加总起来就是基因组。

一开始你从DNA测序仪器上得到了一堆原始乱码数据，就像是你得到了非常多的汉字，但他们是混乱无序的。你想把它们编成一本生命之书，那么就要有章节有目录，要以你能看得懂的语言和句子写成。
所以呢，组装一个基因组，第1步就是你把每个字组装成一句能看得懂的句子，
然后你把每一个句子编成一个段落，de novo assembly，  
再把每一个段落归入各自的章节里面去，
然后再把不同的篇章按照前后顺序组装成这本生命之书。
这里的每一步都对应着组装中的某个技术和算法。
所以说科学都是按照人的思维来进行的，不同的学科都是遵照某种很常识性的原理。

技术其实是很容易掌握的，但美国的教育最启发我的一点是，当我们接到组装一个基因组任务时，我们第一个要问的问题，不是现在有什么方法可以用来组装一个基因组，而是**我们要问最原始的问题，为什么基因组需要组装呢？组装这种思路是靠谱的吗？**

所以我们有必要先了解一下，基因是怎么获得的？难道我们不能直接获得人的整个基因组吗？

测出人的整个基因组，是最直接也最准确的方法，but，技术有限。目前的测序因为测试仪器的局限性只能够把人的这个基因打碎成不同的片段。（目前的测试技术很局限的，所以他们不能够通测基因组，只能够测出上百万亿个小片段，而且每一个片段的长度一般只能在100base pair和300base pair（100bp-300bp）之间。）这就是好比是你从网上你想下载一本电子书，它有100章，但是需要1G，但你的硬盘只能存200M，所以你只好把他们分章下载。生物测序领域的技术相对电子工程没有那么准确，所以你在下载每一章的时候呢，永远都会乱码，并且他们不能以某种特定的顺序来下载。

总而言之，你得到的就是一堆，类似于“武全凑番是误三设肚与凑手今上体楼口咯微邓波儿喇裤伤苦悟@$&@$£#¥€……" 这样的东西。

所以之所以我们要问最原始的问题，为什么基因组需要组装呢？组装这种思路是靠谱的吗？是因为如果我们想要去解决在这个方向上的问题，我们有可能直接去推翻这些问题的前提。

接下里就先说说，如果我们需要组装一个基因组，技术上怎么实现？
介绍完技术才反思一下，这些步骤都存在着怎样的问题？

## wget 从网页上下载原始测序数据

如果是自己的研究，就是直接测序得到数据，进入下一步。这个帖子作为任何人都可以上手去做的，可以从NCBI上下载数据。


主要命令：wget https://sra-pub-run-odp.s3.amazonaws.com/sra/SRR7811197/SRR7811197

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ wget https://sra-pub-run-odp.s3.amazonaws.com/sra/SRR7811197/SRR7811197
--2021-09-23 13:13:09--  https://sra-pub-run-odp.s3.amazonaws.com/sra/SRR7811197/SRR7811197

Resolving sra-pub-run-odp.s3.amazonaws.com (sra-pub-run-odp.s3.amazonaws.com)... 52.216.108.131
Connecting to sra-pub-run-odp.s3.amazonaws.com (sra-pub-run-odp.s3.amazonaws.com)|52.216.108.131|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4057727206 (3.8G) [application/x-troff-man]
Saving to: ‘SRR7811197’

SRR7811197       100%[=========>]   3.78G  3.43MB/s    in 12m 0s  
```



# fastq-dump --split -3 (files)

fastq 是测序得到的数据的格式

> --split-3 separates the reads into left and right ends. If there is a left end without a matching right end, or a right end without a matching left end, they will be put in a single file.
> [bioinformatics notebook] (https://rnnh.github.io/bioinfo-notebook/docs/fastq-dump.html)
> DNA 有双链，从左边读一遍，从右边再读一遍
> dump, Database dump, usually means a record of the table structure and/or the data from a database

主要命令： fastq-dump --split-3 SRR7811197

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ fastq-dump --split-3 SRR7811197 

bg
^C2021-09-23T19:28:27 fastq-dump.2.8.2 sys: libs/kns/unix/syssock.c:492:KSocketTimedRead: transfer interrupted while reading file within network system module - mbedtls_ssl_read returned -26880 ( SSL - Connection requires a read call )
2021-09-23T19:28:28 fastq-dump.2.8.2 err: libs/kapp/unix/sysmain.c:75:Quitting: process canceled while executing process - failed SRR7811197
2021-09-23T19:28:28 fastq-dump.2.8.2 warn: libs/kproc/sem.c:207:KSemaphoreTimedWait: timeout exhausted while waiting semaphore within process system module - libs/kproc/sem.c:207 within KSemaphoreTimedWait

genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ ls
SRR1868103          SRR1868103_2.fastq  SRR7811197_2.fastq
SRR1868103.fastq    SRR7811197
SRR1868103_1.fastq  SRR7811197_1.fastq
```

--split-3 separates the reads into left and right ends. so we get SRR7811197_1.fastq，SRR7811197_2.fastq 

检查得到fastq 是不是相同的长度

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ wc -l *fastq
  11039012 SRR7811197_1.fastq
  11039012 SRR7811197_2.fastq
```

# fastqc 检查数据质量

## 主要命令： fastqc SRR7811197_1.fastq, fastqc SRR7811197_2.fastq

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ fastqc SRR7811197_1.fastq
Started analysis of SRR7811197_1.fastq
Approx 5% complete for SRR7811197_1.fastq
Approx 10% complete for SRR7811197_1.fastq
Approx 15% complete for SRR7811197_1.fastq
Approx 20% complete for SRR7811197_1.fastq
Approx 25% complete for SRR7811197_1.fastq
Approx 30% complete for SRR7811197_1.fastq
Approx 35% complete for SRR7811197_1.fastq
Approx 40% complete for SRR7811197_1.fastq
Approx 45% complete for SRR7811197_1.fastq
Approx 50% complete for SRR7811197_1.fastq
Approx 55% complete for SRR7811197_1.fastq
Approx 60% complete for SRR7811197_1.fastq
Approx 65% complete for SRR7811197_1.fastq
Approx 70% complete for SRR7811197_1.fastq
Approx 75% complete for SRR7811197_1.fastq
Approx 80% complete for SRR7811197_1.fastq
Approx 85% complete for SRR7811197_1.fastq
Approx 90% complete for SRR7811197_1.fastq
Approx 95% complete for SRR7811197_1.fastq
Analysis complete for SRR7811197_1.fastq
```

得到.html .zip 文件，网页是评估的结果

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalplroject$ ls
SRR1868103          SRR1868103_1_fastqc.html  SRR7811197
SRR1868103.fastq    SRR1868103_1_fastqc.zip   SRR7811197_1.fastq
SRR1868103_1.fastq  SRR1868103_2.fastq        SRR7811197_2.fastq
```

将文件从服务器scp 到本地进行查看

```bash
(base) GaoYutingdeMacBook-Air:~ gaoyuting$ scp genomics2021@ruderalis.colorado.edu:~/student_folders/yutigao/finalplroject/SRR1868103_1_fastqc.html ./
genomics2021@ruderalis.colorado.edu's password: 
SRR1868103_1_fastqc.html         100%  720KB   2.1MB/s   00:00    
```

![fastqc 网页](/Users/gaoyuting/Pictures/fatsqc.png)

sequence quality 在绿色区域就证明这批测序的质量是过关的，如果不过关呢？我们就需要进行Trimmomatic

# Trimmomatic 筛选数据

trim v.
remove the edges from and cut down to the desired size
[Trimmomatic: A flexible read trimming tool for Illumina NGS data](http://www.usadellab.org/cms/?page=trimmomatic)

## Trimmomatic commands:

Paired End Mode:
java -jar <path to trimmomatic.jar> PE [-threads <threads] [-phred33 | -phred64] [-trimlog <logFile>] <input 1> <input 2> <paired output 1> <unpaired output 1> <paired output 2> <unpaired output 2> <step 1> ...

如果你想知道这串命令对你的数据做了什么，

> Trimmomatic is a fast, multithreaded command line tool that can be used to trim and cropIllumina (FASTQ) data as well as to remove adapters.  adapter 简要理解就是测序公司为了测序人为加进去的一段DNA序列，就像是钓鱼的时候需要用一条虫先当诱饵。现在我们需要把它从我们的基因组里去掉。

> The paired end mode will maintain correspondence of read pairs and also use the additional
> information contained in paired reads to better find adapter or PCR primer fragments
> introduced by the library preparation proces

> phred + 33 or phred + 64 是quality scores, depending on the Illumina pipeline used

e.g.

```bash
genomics2021@ruderalis:~/student_folders/nolan_kane$ cat command.txt
java -jar ~/trimmomatic-0.39.jar PE -phred33 -trimlog log SRR1868103_1.fastq  SRR1868103_2.fastq SRR1868103_1_paired.fq SRR1868103_1_upaired.fq SRR1868103_2_paired.fq SRR1868103_2_upaired.fq ILLUMINACLIP:TruSeq3-PE.fa:2:20:10 LEADING:20 TRAILING:20 SLIDINGWINDOW:4:15:15 MINLEN:100
```

output: paired.fq unpaired.fq, trim data 的目的是为提高采用的数据的质量, 所以再次fastqc 

```bash
genomics2021@ruderalis:~/student_folders/yutigao/finalproject$ bash trimmomatic.sh
genomics2021@ruderalis:~/student_folders/yutigao/finalproject$ ls
SRR7811197_1_paired_fastqc.zip
SRR7811197_1_unpaired.fq
SRR7811197_2.fastq
SRR7811197_2_paired.fq
SRR7811197_1_paired_fastqc.html
SRR7811197_2_paired_fastqc.html
SRR7811197_2_paired_fastqc.zip
SRR7811197_2_unpaired.fq
SRR7811197_1.fastq           
```

# Pipeline: bwa + samtools + bcftools + grep & awk 

和reference genome 进行比较
bwa, samtools, bcftools 是写好的bioinformatics program, 可以直接在terminal 里敲这些名字来了解怎么使用他们，前提是系统里已经装好了这些东西。

Program: bwa (alignment via Burrows-Wheeler transformation)
Version: 0.7.17-r1188
Contact: Heng Li <lh3@sanger.ac.uk>
Usage:   bwa <command> [options]

Program: samtools (Tools for alignments in the SAM format)
Version: 1.13 (using htslib 1.13)
Usage:   samtools <command> [options]

bcftools
About:   SNP/indel variant calling from VCF/BCF. To be used in conjunction with bcftools mpileup.
         This command replaces the former "bcftools view"
         Usage:   bcftools call [options] <in.vcf.gz>
         

```bash
# bwa index .fa
# bwa mem .fa .fastq > .sam
# samtools view -b -o .bam
# samtools sort .bam > sorted.bam
# samtools index sorted.bam
# samtools faidx sorted.bam
# bcftools mpileup -f .fa .bam| bcftools call -mv -o .vcf
# grep '' .vcf > .txt
# awk '$6>100{print$2,$6}' > goodsnps.txt
```

说明版

```bash
### create bam
bwa index mt.fa
	# bwa index .fa file
	# index sequences in the FASTA format (end in .fa) and create file format in .bwt .pac. ann .amb .sa

bwa mem mt.fa sra_data.fastq > ler.sam
	# bwa mem .fa .fastq > .sam
	# .fasta: sequence
	# .fastq: with quality score

samtools view ler.sam -b -o ler.bam
	# view: SAM<->BAM<->CRAM conversion
	# -b: -bam output in bam format
	# -o: output file
	# -S: sort and read ler.sam output into ler.bam
	# or write in samtools view -b -o ler.bam -S ler.sam

samtools sort ler.bam -o ler.sorted.bam
	# sort bam file

samtools index ler.sorted.bam
	# index alignment

samtools faidx mt.fa
	# fasta index index/ extract fasta
	# creat mt.fa.fai

### make vcf using bcftools
bcftools mpileup -f mt.fa ler.sorted.bam |bcftools call -mv -o ler.vcf
	# save to output file of .bam to
	# multi-way pileup producing genotype likelihoods
	# -f: fasta-ref FILE
	# example: bcftools mpileup -Ou -f reference.fa alignments.bam | bcftools call -mv -Ob -o calls.bcf
	# Ou -- unpressed
	# Ob -- be binary (vcf is text file, bcf is binary file)
	# -m --multiallelic-caller     Alternative model for multiallelic and rare-variant calling (conflicts with -c)
	# -v --Output variant sites only

### grep and awk
grep -v '##' ler.vcf > ler_snps_indels.txt
	# delete ## columns
grep -v 'INDEL' ler.vcf > snps.txt
	# only snps
grep 'INDEL' ler.vcf > indels.txt
awk '$6>100{print$2,$4,$5,$6}' > goodsnps.txt
awk '$6>100{print$2,$4,$5,$6}' indels.txt > goodindels.txt
```

这里用到awk 

# printing in awk: condition{action}

 awk '$6>100{print $4,$5,$6}' snps.txt
also can be:
 awk '$4 == “A” {print $0}' ler.vcf

 In awk, 1 means true and 0 not-true.
  If you type the command below, awk will print all the lines from the file you have selected.
  $ awk ‘1 {print $0}’ ler.vcf (in this case you can remove the default in this case for example {print $0},
  and awk will print the same list.

让你的pipeline 可以重复使用

```bash
ref = organelles.fa
fastq = sra_data.fastq
name = ler
bwa index $ref
bwa mem $ref $fastq > $name.sam
samtools view -b -o $name.bam -S $name.sam
samtools sort $name.bam > $name.sorted.bam
samtools i ndex $name.sorted.bam
samtools faidx $ref
bcftools mpileup -f $ref $name.sorted.bam |bcftools call -mv -o $name.vcf
grep -v '##' $name.vcf > ${name}_snps_indels.txt
grep -v 'INDEL' $name.vcf > snps.txt
grep 'INDEL' $name.vcf > indels.txt
awk '$6>100{print $1,$2,$4,$5,$6}'${name}_snps_indels.txt
 > goodsnps.txt
```

# de novo assembly 从字到段落 

de novo, Latin, literally ‘from new"，也就是从头开始组装基因组 
直到这一步之前，我们所得到的

## De Bruijn Graph

直到这一步之前，我们一直都在准备数据，还没有开始用算法对这些混乱的数据进行排序。

在de novo assembly 里面有非常多的算法，这里采用De Bruijn Graph.

De Bruijn Graph是一种示意图的思路，它可以用来展示不同的序列之间的重叠的关系。比如甲乙丙排排站，怎么样他们会有所在位置上的重叠。同样的，基因组里ATGC4个进行不同的组合他们会有不同的重叠，从而由此来推测他们先后的顺序。有非常多的科学家去解决这个问题，他们所能想到的就是从不同的重叠关系中得到一条最优的路径，从而去得到最初的contig，也就是最初被打破时候的片段。




# SPAdes 

[software SPAdes](https://cab.spbu.ru/software/spades/)
SPAdes 是圣彼得堡

SPAdes 就是建立在De Bruijn Graph基础上，从我们之前得到的数据中提取长度为K的核酸片段，称为K-mer, 然后利用这些K-mer之间重复的部分来构建这个scaffold。

K-mer一定要是奇数。为什么？比如说这条K-mer的数目是17，(17个核苷酸）ATGGGGGCTCTCGAAAA, 那么在运用这个算法的时候，他们首先对这个这个片段正的算一遍，ATGGGGGCTCTCGAAAA，然后反的再算一遍，AAAAGCTCTCGGGGGTA。之所以要算两遍，是因为DNA是有双链，所以比如说在正的ATGGGGGCTCTCGAAAA中的第三个G是属于正的这条链，那你的算法就不能把它归到反链里的第3个去，因为我们可以看反链的AAAAGCTCTCGGGGGTA第三个其实是A。

```bash
head -n 4000000 SRR7811219_1_paired.fq > subset_1.fq
head -n 4000000 SRR7811219_2_paired.fq > subset_2.fq

head -n 400000 mapped_1.fq > subset_mapped_1.fq
head -n 400000 mapped_2.fq > subset_mapped_2.fq
```

## spades --phred-offset 33 --careful -k 21,33,45,55,77 -1 subset_mapped_1.fq -2 subset_mapped_2.fq -o spades4

这里提到了scaffold, contig 等不同的名称，

![scaffold, contig](https://github.com/yuti-gao/yuti-gao.github.io/raw/b280a5aae91b04e56b099822e7383141528def18/_posts/Paired-end%20reads%20span%20gaps.png)

从SPAdes 中我们可以得到一个scaffold.fasta, 由不同的node组成

```bash
>NODE_1_length_61316_cov_90.563334
ACCAATTAATATCATTCAAATTTCTGATCTAAATCACATTGGAAAAAAAATTGTAAAAGC
ACTACGGAATCAAATAAAGGATTTAGAAAATGATAAGACTCATCTTCTCAATGAACGATT
GACTTTGATACAAGATAAGATAGAACAGTCTATTCTTCATCAACCTTCTCTATACAATAC
TAAGTCTGAGGCAAAGAAGGCTAGGAAAGCTAAGAAAAGAAATGTGGATAGCTCACCACA
ACTACCTAAACCTGATGAATAATAGAATTTGGAAATATAAAGTTTCTTGGCCAATTGAGC
GAAGCCAAGCCGTATAAGGGCGTGCAGCACGTATAGCGAGTCAAGGAATAGCAAACGGCC
···
>NODE_2_length_22313_cov_57.552258
GGAAGGTTGCTTTGTTACCTATTCCACTTGGAACCGCGGATTTTTTGGTCCATCACATTC
ATGCATTTACGATTCATGTGACGGTATTGATACTCCTAAAGGGAGTTCTATTTGCCCGCA
GCTCTCGTTTGATACCAGATAAAGCAAATCTGGGTTTTCGCTTCCCTTGTGATGGACCTG
GAAGAGGGGGGACATGTCAAGTATCCGCTTGGGATCATGTCTTCTTAGGATTATTTTGGA
```

这里的length是指有多少个核苷酸，比如AC就是两个核苷酸
cov, coverage, 指的是测序深度

## put nodes in order 

把scaffold.fasta里的node title 去掉，得到一个纯fasta文件，align to reference genome in [NCBI blast](https://blast.ncbi.nlm.nih.gov/Blast.cgi)

![nodes](https://github.com/yuti-gao/yuti-gao.github.io/raw/ae639ff5e1a8d9cf9dca3637980bf8206e4d61b8/_posts/nodes.png)



compare the reference choloplast genome(query genome) with my genome (subject genome)
reorder the nodes sequence from scaffolds according to the graphic summary
make a dotplot





# error correction 

主要是算法，都会有误差。（ALL genomes have mistakes)
经过无数科学家花了超长时间拼出来的、最新的人类基因组第38版，甚至仍存在350个gap。

error correction是我感觉最难的一步。



## Identifying errors

• Align the reads back to the assembly
• Comparison to other genomes or genomic resources
see the tview, to see the quality of the genome we put together 

To correct your genome we will use two approaches.

1. Use zpicture to identify potential errors in the over-all structure. Make sure you do that and understand the results.
   [zpicture](http://zpicture.dcode.org)
2. Align the reads from your fastq files to make sure that the reads
   agree with your assembly. Make a new version of your pipeline that aligns the reads to your cloroplast assembly to identify possible errors -- vcf variant calling 

find the starting point (as circularized)
put the circularized as reference genome
run the SNP calling pipeline again

## reference genome 

[这是我需要用到的reference genome](https://www.ncbi.nlm.nih.gov/nuccore/KY849971.1)

重要的是怎么找到reference genome:

![reference genome](https://github.com/yuti-gao/yuti-gao.github.io/raw/eec0265d0a271befb1e8b124cba863e58f9d66e6/_posts/Screen%20Shot%202022-01-09%20at%209.38.26%20PM.png)



# gap filling 

从上图中可以看到，在拼接的过程中，会产生一些gap, 空缺。

```bash
I’m trying to fill this gap, below, which is 24 bases, between these two contigs.
GTCAAGAATTGGGGCCTCGCAATCACTATTTTATCTCATGCCTTTCTTCGTTCATGGTTC
GATATTCTGGTGTCCTAGGCGTAGAGGAACCACACCAATCCATCCCGAACTTGGTGGTTA
AACTCTACTGCGGTGACGATACTGTAGGGGAGGTCCTGCGGAAAAATAGCTCGACGCCAG
GATGATAAAAAACTTCACACCTCCCGTTCTTCATACTTTTTCAAAAA
(24bp gap)
>NODE_405_length_1788_cov_93.027698
AAATGGCTGAGGAGAGCAAAGGTTCCTTTTTTTGAGGGTACTTCGGGGAACAGATCCAGT
GGAGACGCAGTGGGGCCTGTAGCTCAGAGGATTAGAGCACGTGGCTACGAACCACGGTGT
CGGGGGTTCGAATCCCTCCTCGCCCACAACCGGCCCAAAAGGGAAGGGCCTTTCCCTCTG
GGGGTAGGAAAATCATGATCGGGATAGCGGACCAAAAGCTATGGAACTTGGGTGTGGGTC
TTTTGTCGAAATGGAATGGCCTTTTTCTTTATTATTTATCGTAAATGAGTGAAGCATTAC
ACATAGTATGCCCGTCCCCCATCAGCGTATTTTTTTGTTTTACGCGCCCGTAACTCTTCC
TCAGCCAGGATGGGGCAGAATAGCAGAGCAAGTACAAGTATTAGTAGCATAACAAAAACG
CGTTCCTCGTCATTAATATGTTTGCTCGCGGCAATTGTGGCCTCTCGGTAGAATCGATGA
CTGCATCTTTAGAATCGATGACTGCATCTTTGATGCACTGCTAGTACTAGTACATC
First I’ll try searching for the sequence at the end of the first contig, by going into my folder on the server (ruderalis.colorado.edu) and doing
grep TCATACTTTTTCAAAAA *fastq
Here to help you visualize it, I’ve highlighted that sequence
AACTCTACTGCGGTGACGATACTGTAGGGGAGGTCCTGCGGAAAAATAGCTCGACGCCAG
GATGATAAAAAACTTCACACCTCCCGTTCTTCATACTTTTTCAAAAA
(24bp gap)
>NODE_405_length_1788_cov_93.027698
AAATGGCTGAGGAGAGCAAAGGTTCCTTTTTTTGAGGGTACTTCGGGGAACAGATCCAGT
Anyway, the grep works, and I get back a lot of sequences. Here are the first few lines:
genomics2020@ruderalis:~/student_folders2/nolan/project/carn$ grep
TCATACTTTTTCAAAAA *fastq
mapped_2.fastq:GGTGACGATACTGTAGGGGAGGACCTGCGGAAAAATAGCTCGACGCCAGGATGAT
AAAAAACTTCACACCTCCCGTTCT                 AAAAA
mapped_2.fastq:                 AAAAAAGAAAAATAAAAAGGTCGTCTTATTTAAAACCC
CAATTATGACATCCCCTCTCTCCCACTTCACACCTCGGAACGCGCC
TCATACTTTTTCAAAAA
TCATACTTTTTCAAAAA
  
None of those sequences seem to fill the gap completely. What I am looking for is a read that has the sequence found at the beginning of node 405, and none of the reads have that. So, I have to try to extend my search. Let’s take that second read I got back from the grep, and try to search again, using the sequence from the end of it. Here’s the read, below, and I’ve highlighted the last bases I want to search for in red :
mapped_2.fastq: AAAAAAGAAAAATAAAAAGGTCGTCTTATTTAAAACCC CAATTATGACATCCCCTCTCTCCCACTT
Again, the grep works, and I get back a lot of sequences. Here is the first hit:
genomics2020@ruderalis:~/student_folders2/nolan/project/carn$ grep
CACACCTCGGAACGCGCC *fastq
SRR1868103.1.fastq:CACTT                  GTTCTTATAGAGAGAAAGTAGAGATAAA
GGCGCTTTGAAATCTTCTTAACCCGAAATGGCTGA
That read is good – if I search for the sequence in blue, it is near the beginning of my NODE_405 sequence
>NODE_405_length_1788_cov_93.027698
AAATGGCTGAGGAGAGCAAAGGTTCCTTTTTTTGAGGGTACTTCGGGGAACAGATCCAGT
GGAGACGCAGTGGGGCCTGTAGCTCAGAGGATTAGAGCACGTGGCTACGAACCACGGTGT
CGGGGGTTCGAATCCCTCCTCGCCCACAACCGGCCCAAAAGGGAAGGGCCTTTCCCTCTG
GGGGTAGGAAAATCATGATCGGGATAGCGGACCAAAAGCTATGGAACTTGGGTGTGGGTC
TTTTGTCGAAATGGAATGGCCTTTTTCTTTATTATTTATCGTAAATGAGTGAAGCATTAC
ACATAGTATGCCCGTCCCCCATCAGCGTATTTTTTTGTTTTACGCGCCCGTAACTCTTCC
TCAGCCAGGATGGGGCAGAATAGCAGAGCAAGTACAAGTATTAGTAGCATAACAAAAACG
CGTTCCTCGTCATTAATATGTTTGCTCGCGGCAATTGTGGCCTCTCGGTAGAATCGATGA
CTGCATCTTTAGAATCGATGACTGCATCTTTGATGCACTGCTAGTACTAGTACATC
What that means is that the new sequences I have got from my fastq file fill the gap! I’ll illustrate below how that works by lining them up. The way the second read wraps, it lines up with my node 405 sequence
End of node 50: GATGATAAAAAACTTCACACCTCCCGTTCTTCATACTTTTTCAAAAA First read from the fastq file:
TCATACTTTTTCAAAAAAAAAAAGAAAAATAAAAAGGTCGTCTTATTTAAAACCCCAATTATGACATCCCCTCTCTCCCACTTCACACCTCGGAACGCGCC
TCATACTTTTTCAAAAA
 CACACCTCGGAACGCGCC
 
CACACCTCGGAACGCGCC
 GGAGAGCAAAGGTTC
 
   Second read from the fastq file: AAATGGCTGAGGAGAGCAAAGGTTC
>NODE_405_length_1788_cov_93.027698 AAATGGCTGAGGAGAGCAAAGGTTCCTTTTTTTGAGGGTACTTCGGGGAACAGATCCAGT GGAGACGCAGTGGGGCCTGTAGCTCAGAGGATTAGAGCACGTGGCTACGAACCACGGTGT CGGGGGTTCGAATCCCTCCTCGCCCACAACCGGCCCAAAAGGGAAGGGCCTTTCCCTCTG
SRR1868103.1.fastq:CACTTCACACCTCGGAACGCGCCGTTCTTATAGAGAGAAAGTAGAGATAAAGGCGCTTTGAAATCTTCTTAACCCG
   Now, the last step is to join them all into one sequence, with only one copy wherever there is overlap
End of node 50: GATGATAAAAAACTTCACACCTCCCGTTCTTCATACTTTTTCAAAAAAAAAAAGAAAAATAAAAAGGTCGTCTTATTTAAAACCCCAATTATGACATCCCCTCTCTCCCACTTCACACCTCGGAACGCGCCGTTCTTATAGAGAGAAAGTAGAGATAAAGGCGCTTTGAAATCTTCTTAACCCG AAATGGCTGAGGAGAGCAAAGGTTCCTTTTTTTGAGGGTACTTCGGGGAACAGATCCAGT
GGAGACGCAGTGGGGCCTGTAGCTCAGAGGATTAGAGCACGTGGCTACGAACCACGGTGT
CGGGGGTTCGAATCCCTCCTCGCCCACAACCGGCCCAAAAGGGAAGGGCCTTTCCCTCTG
```



## summary of error correction

结合gap filling的这个方法，整个error correction的流程：

加入rrn16 这个基因的序列和reference genome 不符

1.reference genome找rrn16 

2.copy rr16 sequence, blast rrn16 (reference genome) with my own genome 

3.在alignment 找到plus/plus 首尾， 查找my own genome fasta 

4.gap filling, 在terminal 里 grep '' *fq 

5.修复好plus/plus 之后，reverse complement, 用正确的reverse complement 的首尾查找my genome fasta (一般plus/minus 首尾是健在的，只是缺少中间的一些部分)，这一步只是要找到reverse complement(inverted repeat)的位置

6. 用正确的reverse complement直接替换掉plus/minus



# genome annotation 

这一教程以叶绿体基因组组装为例

[chloroplast annotation](https://chlorobox.mpimp-golm.mpg.de/geseq.html)

得到一堆文件，其中我们看genbank file, 和直观的circular genome

![o](https://github.com/yuti-gao/yuti-gao.github.io/raw/812ad05fb7f8aade4e79645265125cdc3e8d65f9/_posts/1102_norinum_25_flax_SSR220_OGDRAW.jpg)

从这张图里我们可以和reference genome 的paper进行对比，发现有几个问题：

1.fragment (这个基因的片段是破碎的)

2.inverse repeat not identical （inverse repeat 应该是一模一样的）

3.tRNA annotated repeatedly 

通过annotation 也可以再一次检验 error correction 这一步骤是否彻底





functional annotation: compare the similarity  



